# ğŸ“ Zincirleme Etki (Chain Reaction) Oyunu iÃ§in Minimax AI Raporu

## 1. GiriÅŸ

Bu rapor, Pygame kÃ¼tÃ¼phanesi kullanÄ±larak geliÅŸtirilen ve Alpha-Beta BudamalÄ± Minimax algoritmasÄ± ile gÃ¼Ã§lendirilmiÅŸ bir yapay zeka (AI) ajanÄ± iÃ§eren Zincirleme Etki (Chain Reaction) tahta oyununun teknik uygulamasÄ±nÄ± detaylandÄ±rmaktadÄ±r. Projenin temel amacÄ±, klasik bir strateji oyunu ortamÄ±nda en iyi hamleyi bulabilen verimli bir AI ajanÄ± oluÅŸturmaktÄ±r.

## 2. Oyun Mekanikleri ve Uygulama (OyunTahtasi SÄ±nÄ±fÄ±)

### 2.1. Tahta Temsili ve Oyuncu Kimlikleri

Oyun tahtasÄ±, 8x8 boyutlarÄ±nda bir matris (`self.tahta`) ile temsil edilir. Karelerin deÄŸerleri, hangi oyuncuya ait olduÄŸunu gÃ¶steren kimlik (ID) numaralarÄ± ile temsil edilir:

* **BoÅŸ Kare:** `0`
* **AI (KÄ±rmÄ±zÄ±):** `1` (`self.ai_id`)
* **Ä°nsan Oyuncu (Mavi):** `2` (`self.insan_id`)

Oyuncu sÄ±rasÄ±, `self.oyuncu_sira = 3 - oyuncu_id` basit aritmetik formÃ¼lÃ¼ kullanÄ±larak tutarlÄ± bir ÅŸekilde deÄŸiÅŸtirilir.

### 2.2. Zincirleme Etki MekaniÄŸi (`zincirleme_etkiyi_kontrol_et`)

Oyunun temel mekaniÄŸi, bir oyuncunun hamlesi sonrasÄ± yatay, dikey veya Ã§apraz yÃ¶nde 4 veya daha fazla puldan oluÅŸan zincirleri tespit etmektir.

* **Puanlama:** OluÅŸturulan zincirdeki pul sayÄ±sÄ± kadar oyuncunun skoruna puan eklenir.
* **Tahtadan KaldÄ±rma:** Puanlanan zincirdeki tÃ¼m pullar, puanlama tamamlandÄ±ktan sonra tahtadan kaldÄ±rÄ±lÄ±r (`0` olarak ayarlanÄ±r), bu da stratejik boÅŸluklar yaratarak oyuna dinamizm katar.

### 2.3. Oyun Sonu KoÅŸullarÄ±

Oyun iki ana koÅŸuldan biri gerÃ§ekleÅŸtiÄŸinde sona erer:

1.  **Skor Limiti:** Bir oyuncunun skoru belirlenen limite (`limit_skor = 30`) ulaÅŸtÄ±ÄŸÄ±nda.
2.  **Tahta DoluluÄŸu:** Tahtada geÃ§erli hamle kalmadÄ±ÄŸÄ±nda (tÃ¼m kareler dolduÄŸunda). Bu durumda en yÃ¼ksek skora sahip oyuncu kazanÄ±r.

## 3. Yapay Zeka AjanÄ± (MinimaxAgent SÄ±nÄ±fÄ±)

AI ajanÄ±, tam bilgiye sahip, sÄ±fÄ±r toplamlÄ± bu oyun iÃ§in optimal stratejiyi bulmaya Ã§alÄ±ÅŸan **Minimax algoritmasÄ±nÄ±** kullanÄ±r.

### 3.1. Minimax AlgoritmasÄ±

Minimax, her bir oyun durumu iÃ§in sayÄ±sal bir deÄŸer (skor) atayarak, AI'Ä±n kazancÄ±nÄ± maksimize etmeye ve rakibin (Ä°nsan) kazancÄ±nÄ± minimize etmeye odaklanÄ±r.

* **Maksimize Eden Oyuncu (Maximizing Player):** AI (`self.ai_id = 1`). AmacÄ± en yÃ¼ksek skoru bulmaktÄ±r.
* **Minimize Eden Oyuncu (Minimizing Player):** Ä°nsan (`self.insan_id = 2`). AmacÄ± AI iÃ§in en dÃ¼ÅŸÃ¼k skoru bulmaktÄ±r.
* **Derinlik (`derinlik`):** AjanÄ±n ne kadar ileriye bakacaÄŸÄ±nÄ± belirler. Bu projede **varsayÄ±lan derinlik 2** olarak ayarlanmÄ±ÅŸtÄ±r.

### 3.2. Alpha-Beta BudamasÄ± (Alpha-Beta Pruning)

Minimax arama aÄŸacÄ±nÄ±n verimliliÄŸini artÄ±rmak iÃ§in **Alpha-Beta BudamasÄ±** tekniÄŸi uygulanmÄ±ÅŸtÄ±r.

* **Alpha DeÄŸeri:** Maksimize eden oyuncunun (AI) o ana kadar bulduÄŸu en iyi garantili skor.
* **Beta DeÄŸeri:** Minimize eden oyuncunun (Ä°nsan) o ana kadar bulduÄŸu en kÃ¶tÃ¼ (AI iÃ§in) garantili skor.
* **Budama KoÅŸulu:** EÄŸer **Beta $\le$ Alpha** ise, aÄŸacÄ±n mevcut dalÄ± daha fazla incelenmeden kesilir (budanÄ±r), Ã§Ã¼nkÃ¼ bu dalÄ±n daha kÃ¶tÃ¼ bir sonuÃ§ vereceÄŸi garantilenmiÅŸtir. Bu, arama sÃ¼resini Ã¶nemli Ã¶lÃ§Ã¼de kÄ±saltÄ±r.

### 3.3. DeÄŸerlendirme Fonksiyonu (Heuristik)

Oyun sonu durumlarÄ±nda kesin skorlar verilirken ($10^6$ ve $-10^6$), ara durumlarda tahtayÄ± sayÄ±sal olarak deÄŸerlendiren bir sezgisel (heuristik) fonksiyon (`degerlendirme_fonksiyonu`) kullanÄ±lÄ±r.

$$
\text{Skor} = (\text{AI Skor} - \text{Ä°nsan Skor}) \times 100 + \text{Merkez DeÄŸeri}
$$

**Heuristik BileÅŸenleri:**

1.  **Skor FarkÄ± ($\times 100$):** Mevcut skor farkÄ±, tahtanÄ±n mevcut durumunun ana belirleyicisidir ve aÄŸÄ±rlÄ±klandÄ±rÄ±larak (100 ile Ã§arpÄ±larak) Ã¶nceliklendirilir.
2.  **Merkez KontrolÃ¼ (Merkez DeÄŸeri):** TahtanÄ±n merkezi kareleri $[(3, 3), (3, 4), (4, 3), (4, 4)]$ stratejik Ã¶neme sahiptir. Bu karelere sahip olmak AI iÃ§in $+5$, Ä°nsan iÃ§in $-5$ puan olarak eklenir.

## 4. SonuÃ§ ve GeliÅŸtirme Ã–nerileri

Bu projede, Minimax algoritmasÄ± ve Alpha-Beta BudamasÄ± kullanÄ±larak Chain Reaction oyun kurallarÄ±na uyan gÃ¼Ã§lÃ¼ bir AI ajanÄ± baÅŸarÄ±yla oluÅŸturulmuÅŸtur. AI, Ã¶zellikle merkez kontrolÃ¼nÃ¼ ve skor farkÄ±nÄ± maksimize etmeye odaklanan sezgisel fonksiyon sayesinde stratejik hamleler yapabilmektedir.

### GeliÅŸtirme Ã–nerileri:

* **Derinlik ArtÄ±ÅŸÄ±:** DonanÄ±m elverdiÄŸince arama derinliÄŸini artÄ±rmak, AI'Ä±n Ã¶ngÃ¶rÃ¼sÃ¼nÃ¼ ve performansÄ±nÄ± yÃ¼kseltir.
* **GeliÅŸmiÅŸ Heuristik:** Kenar pullarÄ±na sahip olmaya ek puan vermek veya zincir potansiyelini (3'lÃ¼ veya 2'li gruplarÄ±n sayÄ±sÄ±nÄ±) hesaba katmak gibi daha karmaÅŸÄ±k sezgisel faktÃ¶rler eklenebilir.
* **Ä°teratif DerinleÅŸtirme:** Daha uzun sÃ¼reli dÃ¼ÅŸÃ¼nme sÃ¼relerinde dahi stabil tepki sÃ¼releri saÄŸlamak iÃ§in Minimax'a Ä°teratif DerinleÅŸtirme (Iterative Deepening) tekniÄŸi uygulanabilir.